{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umair594/100-Prediction-Models-/blob/main/Stepwise_Regression_%E2%80%93_Feature_Selection_Through_Iterative_Inclusion_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project 10: Stepwise Regression ‚Äì Feature Selection Through Iterative Inclusion**"
      ],
      "metadata": {
        "id": "WeSR5w5myzGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract**\n",
        "\n",
        "Stepwise Regression is a systematic method for selecting important features in a regression model. It iteratively adds or removes predictors based on statistical criteria such as the p-value or AIC/BIC. This project explores the theory, implementation, and evaluation of Stepwise Regression using Python. The goal is to improve model interpretability, reduce overfitting, and identify the most significant predictors. Implementation on a synthetic dataset demonstrates how stepwise selection helps construct a parsimonious and effective regression model."
      ],
      "metadata": {
        "id": "3n8mH1d5y7Ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "In regression modeling, including all available features can lead to:\n",
        "\n",
        "Overfitting\n",
        "\n",
        "Multicollinearity\n",
        "\n",
        "Poor interpretability\n",
        "\n",
        "Stepwise Regression addresses this by iteratively including or excluding features based on their contribution to model performance. There are three main approaches:\n",
        "\n",
        "Forward Selection ‚Äì Start with no predictors, add features one at a time based on improvement in criteria (e.g., p-value, AIC).\n",
        "\n",
        "Backward Elimination ‚Äì Start with all predictors, remove the least significant feature iteratively.\n",
        "\n",
        "Bidirectional / Stepwise Selection ‚Äì Combination of forward and backward methods.\n",
        "\n",
        "This project demonstrates stepwise regression (forward selection) for feature selection in linear regression."
      ],
      "metadata": {
        "id": "_E3fRTyLy96Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theoretical Background**\n",
        "\n",
        "Linear Regression\n",
        "\n",
        "Linear regression predicts a continuous response variable\n",
        "ùë¶\n",
        "y as a linear combination of predictors\n",
        "ùëã\n",
        "1\n",
        ",\n",
        "ùëã\n",
        "2\n",
        ",\n",
        ".\n",
        ".\n",
        ".\n",
        ",\n",
        "ùëã\n",
        "ùëõ\n",
        "X\n",
        "1\n",
        "\t‚Äã\n",
        "\n",
        ",X\n",
        "2\n",
        "\t‚Äã\n",
        "\n",
        ",...,X\n",
        "n\n",
        "\t‚Äã\n",
        "\n",
        ":\n",
        "\n",
        "ùõΩ\n",
        "ùëñ\n",
        "Œ≤\n",
        "i\n",
        "\t‚Äã\n",
        "\n",
        " = regression coefficients\n",
        "\n",
        "ùúñ\n",
        "œµ = error term"
      ],
      "metadata": {
        "id": "SSpEko7yzAyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stepwise Regression**\n",
        "\n",
        "Stepwise regression iteratively evaluates feature significance:\n",
        "\n",
        "Forward Selection: Add features with p-value < threshold (commonly 0.05)\n",
        "\n",
        "Backward Elimination: Remove features with p-value > threshold\n",
        "\n",
        "Stepwise: Combination of both\n",
        "\n",
        "It reduces dimensionality while maintaining predictive power."
      ],
      "metadata": {
        "id": "0PRkZiImzJMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Criteria for Feature Inclusion/Exclusion**\n",
        "\n",
        "p-value: Probability that coefficient is zero (statistical significance)\n",
        "\n",
        "AIC / BIC: Penalized likelihood criteria to balance model fit and complexity"
      ],
      "metadata": {
        "id": "aZtaEuUTzTZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Methodology**\n",
        "\n",
        "Steps in this project:\n",
        "\n",
        "Generate a synthetic regression dataset with multiple predictors.\n",
        "\n",
        "Split the dataset into training and testing sets.\n",
        "\n",
        "Implement forward stepwise regression using p-values.\n",
        "\n",
        "Fit the selected features using OLS regression.\n",
        "\n",
        "Evaluate model performance using R¬≤ and RMSE.\n",
        "\n",
        "Analyze selected features and their coefficients."
      ],
      "metadata": {
        "id": "iN0Vr0wPzVtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Python Implementation**"
      ],
      "metadata": {
        "id": "lnAzNh4qzYBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "iNHwoRkAzaqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "I4LbJlgBzcaQ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Dataset**"
      ],
      "metadata": {
        "id": "6WMMQRcNzfbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic regression dataset\n",
        "X, y = make_regression(\n",
        "    n_samples=200,\n",
        "    n_features=10,\n",
        "    n_informative=5,\n",
        "    noise=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "X = pd.DataFrame(X, columns=[f'X{i}' for i in range(1, 11)])\n",
        "y = pd.Series(y, name='y')"
      ],
      "metadata": {
        "id": "qFDiaHKMzhkQ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-Test Split**"
      ],
      "metadata": {
        "id": "RHRgL490zjTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "L21V5Zs4zlT4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stepwise Regression Function (Forward Selection)**"
      ],
      "metadata": {
        "id": "LHeMNYiLzms5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_selection(X, y, significance_level=0.05):\n",
        "    initial_features = []\n",
        "    remaining_features = list(X.columns)\n",
        "    selected_features = []\n",
        "\n",
        "    while remaining_features:\n",
        "        p_values = pd.Series(index=remaining_features)\n",
        "        for feature in remaining_features:\n",
        "            model = sm.OLS(y, sm.add_constant(X[initial_features + [feature]])).fit()\n",
        "            p_values[feature] = model.pvalues[feature]\n",
        "        min_p_value = p_values.min()\n",
        "        if min_p_value < significance_level:\n",
        "            best_feature = p_values.idxmin()\n",
        "            initial_features.append(best_feature)\n",
        "            selected_features.append(best_feature)\n",
        "            remaining_features.remove(best_feature)\n",
        "        else:\n",
        "            break\n",
        "    return selected_features"
      ],
      "metadata": {
        "id": "yh_mqBU7zpCQ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply Forward Selection**"
      ],
      "metadata": {
        "id": "X4jF4Bllzqvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = forward_selection(X_train, y_train)\n",
        "print(\"Selected features:\", selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTLxTGZlzs1g",
        "outputId": "96c1f711-e40a-4856-f323-44619b91a22c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: ['X4', 'X8', 'X6', 'X3', 'X7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fit Final Model with Selected Features**"
      ],
      "metadata": {
        "id": "432A0gzTzuaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_selected = sm.add_constant(X_train[selected_features])\n",
        "X_test_selected = sm.add_constant(X_test[selected_features])\n",
        "\n",
        "final_model = sm.OLS(y_train, X_train_selected).fit()\n",
        "print(final_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlGcLHDizwnI",
        "outputId": "9a59edcc-c8b3-4145-8070-642b47791f04"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.991\n",
            "Model:                            OLS   Adj. R-squared:                  0.991\n",
            "Method:                 Least Squares   F-statistic:                     3341.\n",
            "Date:                Sat, 07 Feb 2026   Prob (F-statistic):          4.81e-155\n",
            "Time:                        06:34:29   Log-Likelihood:                -586.10\n",
            "No. Observations:                 160   AIC:                             1184.\n",
            "Df Residuals:                     154   BIC:                             1203.\n",
            "Df Model:                           5                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -1.0306      0.769     -1.341      0.182      -2.549       0.488\n",
            "X4            80.5896      0.789    102.097      0.000      79.030      82.149\n",
            "X8            40.5373      0.837     48.436      0.000      38.884      42.191\n",
            "X6            35.6965      0.769     46.449      0.000      34.178      37.215\n",
            "X3             9.1807      0.778     11.799      0.000       7.644      10.718\n",
            "X7             7.7330      0.712     10.854      0.000       6.326       9.140\n",
            "==============================================================================\n",
            "Omnibus:                        1.224   Durbin-Watson:                   1.929\n",
            "Prob(Omnibus):                  0.542   Jarque-Bera (JB):                1.279\n",
            "Skew:                          -0.204   Prob(JB):                        0.528\n",
            "Kurtosis:                       2.839   Cond. No.                         1.39\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predictions and Evaluation**"
      ],
      "metadata": {
        "id": "2T2-WgSZzykI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = final_model.predict(X_test_selected)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(\"R¬≤:\", r2)\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHUiiOZez2Vo",
        "outputId": "13b0728f-3522-4f28-f02a-e9cb9ecd4c12"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R¬≤: 0.987197260033537\n",
            "RMSE: 8.782209520477359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results and Discussion**\n",
        "\n",
        "Selected Features: Only statistically significant predictors are included.\n",
        "\n",
        "Model Fit: R¬≤ indicates proportion of variance explained.\n",
        "\n",
        "Error Metric: RMSE measures prediction accuracy on test data.\n",
        "\n",
        "Stepwise regression reduces dimensionality while maintaining predictive performance.\n",
        "\n",
        "Coefficients indicate the strength and direction of selected predictors."
      ],
      "metadata": {
        "id": "RHEi8eTiz6Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages**\n",
        "\n",
        "Reduces overfitting by excluding irrelevant features.\n",
        "\n",
        "Improves interpretability of the model.\n",
        "\n",
        "Automates feature selection in a systematic way."
      ],
      "metadata": {
        "id": "s8vZw_M4z85h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limitations**\n",
        "\n",
        "Stepwise regression can be greedy ‚Äî may miss optimal feature combination.\n",
        "\n",
        "Sensitive to p-value threshold.\n",
        "\n",
        "May not perform well with highly correlated features."
      ],
      "metadata": {
        "id": "Rp4DEEOZz-4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "Stepwise regression is an effective approach for feature selection in regression modeling. By iteratively adding or removing predictors based on statistical significance, the method produces a parsimonious model that balances interpretability and predictive power. In this project, stepwise regression was implemented in Python and successfully identified the most significant features while maintaining strong model performance."
      ],
      "metadata": {
        "id": "zFNKk7Ne0B_4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}